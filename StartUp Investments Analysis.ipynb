{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "63041464-0d55-4f5d-9786-c7e4df271e50",
      "cell_type": "code",
      "source": "# data_processor.py\nimport pandas as pd\nimport numpy as np\n\n# --- Configuration ---\n# Ensure this matches your downloaded file name from Kaggle\nINPUT_CSV_PATH = 'investments_VC.csv'\nOUTPUT_CLEANED_CSV_PATH = 'cleaned_investments.csv'\n\n# --- Load Data ---\ndef load_data(file_path):\n    \"\"\"\n    Loads the raw dataset from a CSV file.\n    Handles potential encoding issues common with this dataset.\n    \"\"\"\n    print(f\"Loading data from {file_path}...\")\n    try:\n        # The dataset is known to sometimes have 'latin1' encoding issues.\n        # If 'utf-8' fails, 'latin1' or 'iso-8859-1' are good alternatives to try.\n        df = pd.read_csv(file_path, encoding='latin1')\n        print(\"Data loaded successfully.\")\n        return df\n    except FileNotFoundError:\n        print(f\"ERROR: File not found at {file_path}. Please ensure the dataset is in the correct location and the INPUT_CSV_PATH is correct.\")\n        return None\n    except Exception as e:\n        print(f\"ERROR: An error occurred while loading the data: {e}\")\n        return None\n\n# --- Clean Data ---\ndef clean_data(df):\n    \"\"\"\n    Cleans the input DataFrame:\n    - Standardizes column names.\n    - Cleans and converts 'funding_total_usd'.\n    - Cleans 'country_code' (renames to 'country') and handles missing values.\n    - Extracts 'primary_category' from 'category_list'.\n    - Converts date columns to datetime objects and extracts years.\n    - Cleans 'status' and 'funding_rounds'.\n    - Drops rows with critical missing data for analysis (e.g., funding_total_usd, first_funding_year).\n    \"\"\"\n    if df is None:\n        print(\"No DataFrame provided to clean_data function. Skipping.\")\n        return None\n    print(\"Starting data cleaning...\")\n    df_cleaned = df.copy()\n\n    # 1. Standardize column names\n    # Remove leading/trailing spaces, convert to lowercase, replace spaces with underscores.\n    df_cleaned.columns = df_cleaned.columns.str.strip().str.lower().str.replace(' ', '_')\n    print(\"Standardized column names.\")\n\n    # 2. Handle 'funding_total_usd'\n    # This is a critical column for almost all analyses.\n    if 'funding_total_usd' in df_cleaned.columns:\n        print(\"Cleaning 'funding_total_usd'...\")\n        # Original data has ' - ' for missing and commas as thousands separators.\n        df_cleaned['funding_total_usd'] = df_cleaned['funding_total_usd'].astype(str).str.replace(',', '')\n        df_cleaned['funding_total_usd'] = df_cleaned['funding_total_usd'].replace(' - ', np.nan) # Ensure '-' is treated as NaN\n        df_cleaned['funding_total_usd'] = pd.to_numeric(df_cleaned['funding_total_usd'], errors='coerce')\n\n        initial_rows = len(df_cleaned)\n        df_cleaned.dropna(subset=['funding_total_usd'], inplace=True) # Essential for funding analysis\n        print(f\"Dropped {initial_rows - len(df_cleaned)} rows with missing/invalid 'funding_total_usd'.\")\n    else:\n        print(\"WARNING: 'funding_total_usd' column not found after standardization. Check original column names and adjust if necessary.\")\n        # This is a critical failure point if the column isn't found.\n\n    # 3. Handle 'country_code' (often used as 'country')\n    if 'country_code' in df_cleaned.columns:\n        print(\"Cleaning 'country_code' and renaming to 'country'...\")\n        df_cleaned.rename(columns={'country_code': 'country'}, inplace=True)\n        df_cleaned['country'] = df_cleaned['country'].str.strip()\n        # Drop rows where country is missing, as it's important for geographical analysis\n        initial_rows_country = len(df_cleaned)\n        df_cleaned.dropna(subset=['country'], inplace=True)\n        print(f\"Dropped {initial_rows_country - len(df_cleaned)} rows with missing 'country'.\")\n        print(\"Cleaned 'country'.\")\n    else:\n        print(\"WARNING: 'country_code' column not found.\")\n\n\n    # 4. Handle 'category_list' (extract primary category)\n    if 'category_list' in df_cleaned.columns:\n        print(\"Extracting 'primary_category' from 'category_list'...\")\n        # Take the first category before the '|' delimiter.\n        df_cleaned['primary_category'] = df_cleaned['category_list'].astype(str).apply(\n            lambda x: x.split('|')[0].strip() if pd.notnull(x) and '|' in x else (x.strip() if pd.notnull(x) else 'Unknown')\n        )\n        # Handle cases where category might be empty string or 'nan' after split\n        df_cleaned['primary_category'] = df_cleaned['primary_category'].replace({'nan': 'Unknown', '': 'Unknown'})\n        df_cleaned.loc[df_cleaned['primary_category'].isnull(), 'primary_category'] = 'Unknown'\n        print(\"Extracted 'primary_category'.\")\n    else:\n        print(\"WARNING: 'category_list' column not found.\")\n\n    # 5. Handle Date Columns\n    date_cols_to_process = ['founded_at', 'first_funding_at', 'last_funding_at']\n    print(f\"Cleaning date columns: {date_cols_to_process}...\")\n    for col in date_cols_to_process:\n        if col in df_cleaned.columns:\n            df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors='coerce')\n            # Extract year for easier filtering and aggregation in Streamlit\n            # Using .dt.year will result in float if there are NaT values, then convert to Int64 to support NA\n            year_col_name = col.replace('_at', '_year')\n            df_cleaned[year_col_name] = df_cleaned[col].dt.year.astype('Int64') # Int64 supports pandas NA\n        else:\n            print(f\"WARNING: Date column '{col}' not found.\")\n    print(\"Cleaned date columns and extracted years.\")\n\n    # 6. Clean 'status' column\n    if 'status' in df_cleaned.columns:\n        print(\"Cleaning 'status' column...\")\n        df_cleaned['status'] = df_cleaned['status'].fillna('unknown').str.lower()\n        # Consolidate status values if needed (e.g., map variations to standard terms)\n        # Common values are 'operating', 'acquired', 'closed', 'ipo'.\n        valid_statuses = ['operating', 'acquired', 'closed', 'ipo']\n        df_cleaned['status'] = df_cleaned['status'].apply(lambda x: x if x in valid_statuses else 'unknown')\n        print(\"Cleaned 'status' column.\")\n    else:\n        print(\"WARNING: 'status' column not found.\")\n\n    # 7. Clean 'funding_rounds'\n    if 'funding_rounds' in df_cleaned.columns:\n        print(\"Cleaning 'funding_rounds'...\")\n        df_cleaned['funding_rounds'] = pd.to_numeric(df_cleaned['funding_rounds'], errors='coerce')\n        df_cleaned.dropna(subset=['funding_rounds'], inplace=True) # Drop if not a number\n        df_cleaned['funding_rounds'] = df_cleaned['funding_rounds'].astype(int)\n        print(\"Cleaned 'funding_rounds'.\")\n    else:\n        print(\"WARNING: 'funding_rounds' column not found.\")\n\n    # 8. Rename 'name' if it's messy (e.g. 'name ' with space)\n    # Check if a common problematic name like 'name ' (with trailing space) exists and 'name' does not\n    if 'name ' in df_cleaned.columns and 'name' not in df_cleaned.columns:\n        df_cleaned.rename(columns={'name ': 'name'}, inplace=True)\n        print(\"Renamed 'name ' to 'name'.\")\n    elif 'name' not in df_cleaned.columns:\n         print(\"WARNING: Standard 'name' column not found. Company identification might be affected.\")\n\n\n    # 9. Drop rows where 'first_funding_year' is NaN as it's critical for many time-based analyses\n    if 'first_funding_year' in df_cleaned.columns:\n        initial_rows_ffy = len(df_cleaned)\n        df_cleaned.dropna(subset=['first_funding_year'], inplace=True)\n        # After dropping NaNs, we can safely convert to int if it's Int64\n        df_cleaned['first_funding_year'] = df_cleaned['first_funding_year'].astype(int)\n        print(f\"Dropped {initial_rows_ffy - len(df_cleaned)} rows with missing 'first_funding_year'.\")\n    else:\n        print(\"WARNING: 'first_funding_year' column not found or not processed. Time-based analysis will be affected.\")\n\n\n    print(f\"Data cleaning completed. Shape of cleaned data: {df_cleaned.shape}\")\n    print(\"\\n--- Missing Values Summary (Top 10) After Cleaning ---\")\n    # Display columns with the most missing values after cleaning\n    missing_summary = df_cleaned.isnull().sum()\n    missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)\n    print(missing_summary.head(10))\n    return df_cleaned\n\n# --- Perform EDA (Conceptual - details in Analysis Report) ---\ndef perform_basic_eda(df):\n    \"\"\"\n    Performs and prints basic Exploratory Data Analysis results.\n    This is a lightweight EDA; more detailed EDA should be in the Analysis Report.\n    \"\"\"\n    if df is None or df.empty:\n        print(\"Skipping EDA as data is not available or empty.\")\n        return\n\n    print(\"\\n--- Basic Exploratory Data Analysis (EDA) ---\")\n\n    if 'funding_total_usd' in df.columns:\n        print(\"\\n--- Descriptive Statistics for 'funding_total_usd' ---\")\n        print(df['funding_total_usd'].describe())\n    else:\n        print(\"'funding_total_usd' not found for EDA.\")\n\n    if 'primary_category' in df.columns:\n        print(\"\\n--- Value Counts for Top 5 Primary Categories ---\")\n        print(df['primary_category'].value_counts().nlargest(5))\n    else:\n        print(\"'primary_category' not found for EDA.\")\n\n    if 'country' in df.columns:\n        print(\"\\n--- Value Counts for Top 5 Countries ---\")\n        print(df['country'].value_counts().nlargest(5))\n    else:\n        print(\"'country' not found for EDA.\")\n\n    if 'status' in df.columns:\n        print(\"\\n--- Value Counts for Company Status ---\")\n        print(df['status'].value_counts())\n    else:\n        print(\"'status' not found for EDA.\")\n\n    # Check availability of data for potential KPIs (to be visualized in Streamlit)\n    print(\"\\n--- Data Check for Potential KPIs ---\")\n    kpi_columns_to_check = {\n        \"Total Funding by Year\": ['first_funding_year', 'funding_total_usd'],\n        \"Top N Countries by Funding\": ['country', 'funding_total_usd'],\n        \"Top N Categories by Funding\": ['primary_category', 'funding_total_usd'],\n        \"Funding by Company Status\": ['status', 'funding_total_usd'],\n        \"Average Funding per Round\": ['funding_total_usd', 'funding_rounds'],\n        \"Number of Investments Over Time\": ['first_funding_year', 'name'], # Using 'name' as a proxy for unique investment\n        \"Distribution of Funding Amounts\": ['funding_total_usd'],\n        \"Funding Rounds vs. Total Funding\": ['funding_rounds', 'funding_total_usd'],\n        \"Top Cities by Investment (if 'city' available)\": ['city', 'funding_total_usd'],\n        \"Time from Founding to First Funding\": ['founded_year', 'first_funding_year']\n    }\n    for kpi, cols in kpi_columns_to_check.items():\n        missing_cols = [col for col in cols if col not in df.columns or df[col].isnull().all()]\n        if not missing_cols:\n            print(f\"Data for KPI '{kpi}': Seems available.\")\n        else:\n            print(f\"Data for KPI '{kpi}': MISSING or all NaNs for columns: {missing_cols}\")\n\n\n# --- Main Execution Block ---\nif __name__ == \"__main__\":\n    print(\"--- Starting Startup Investment Data Processing ---\")\n    raw_df = load_data(INPUT_CSV_PATH)\n\n    if raw_df is not None:\n        print(\"\\n--- Initial Data Info (First 5 Rows & Column Info) ---\")\n        print(\"Head of raw data:\")\n        print(raw_df.head())\n        print(\"\\nInfo of raw data:\")\n        raw_df.info(verbose=True, show_counts=True) # More detailed info\n\n        cleaned_df = clean_data(raw_df)\n\n        if cleaned_df is not None and not cleaned_df.empty:\n            perform_basic_eda(cleaned_df)\n            # Save the cleaned data to a new CSV file\n            try:\n                cleaned_df.to_csv(OUTPUT_CLEANED_CSV_PATH, index=False)\n                print(f\"\\nCleaned data successfully saved to '{OUTPUT_CLEANED_CSV_PATH}'\")\n            except Exception as e:\n                print(f\"ERROR: Could not save cleaned data: {e}\")\n        else:\n            print(\"Cleaned data is empty or None. Not performing EDA or saving.\")\n    else:\n        print(\"Raw data could not be loaded. Processing halted.\")\n    print(\"--- End of Startup Investment Data Processing ---\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "--- Starting Startup Investment Data Processing ---\nLoading data from investments_VC.csv...\nData loaded successfully.\n\n--- Initial Data Info (First 5 Rows & Column Info) ---\nHead of raw data:\n                         permalink                name  \\\n0            /organization/waywire            #waywire   \n1  /organization/tv-communications  &TV Communications   \n2    /organization/rock-your-paper   'Rock' Your Paper   \n3   /organization/in-touch-network   (In)Touch Network   \n4   /organization/r-ranch-and-mine  -R- Ranch and Mine   \n\n                    homepage_url  \\\n0         http://www.waywire.com   \n1          http://enjoyandtv.com   \n2   http://www.rockyourpaper.org   \n3  http://www.InTouchNetwork.com   \n4                            NaN   \n\n                                       category_list        market   \\\n0         |Entertainment|Politics|Social Media|News|          News    \n1                                            |Games|         Games    \n2                             |Publishing|Education|    Publishing    \n3  |Electronics|Guides|Coffee|Restaurants|Music|i...   Electronics    \n4                      |Tourism|Entertainment|Games|       Tourism    \n\n   funding_total_usd      status country_code state_code         region  ...  \\\n0          17,50,000    acquired          USA         NY  New York City  ...   \n1          40,00,000   operating          USA         CA    Los Angeles  ...   \n2             40,000   operating          EST        NaN        Tallinn  ...   \n3          15,00,000   operating          GBR        NaN         London  ...   \n4             60,000   operating          USA         TX         Dallas  ...   \n\n  secondary_market  product_crowdfunding round_A round_B round_C  round_D  \\\n0              0.0                   0.0     0.0     0.0     0.0      0.0   \n1              0.0                   0.0     0.0     0.0     0.0      0.0   \n2              0.0                   0.0     0.0     0.0     0.0      0.0   \n3              0.0                   0.0     0.0     0.0     0.0      0.0   \n4              0.0                   0.0     0.0     0.0     0.0      0.0   \n\n  round_E round_F  round_G  round_H  \n0     0.0     0.0      0.0      0.0  \n1     0.0     0.0      0.0      0.0  \n2     0.0     0.0      0.0      0.0  \n3     0.0     0.0      0.0      0.0  \n4     0.0     0.0      0.0      0.0  \n\n[5 rows x 39 columns]\n\nInfo of raw data:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 54294 entries, 0 to 54293\nData columns (total 39 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   permalink             49438 non-null  object \n 1   name                  49437 non-null  object \n 2   homepage_url          45989 non-null  object \n 3   category_list         45477 non-null  object \n 4    market               45470 non-null  object \n 5    funding_total_usd    49438 non-null  object \n 6   status                48124 non-null  object \n 7   country_code          44165 non-null  object \n 8   state_code            30161 non-null  object \n 9   region                44165 non-null  object \n 10  city                  43322 non-null  object \n 11  funding_rounds        49438 non-null  float64\n 12  founded_at            38554 non-null  object \n 13  founded_month         38482 non-null  object \n 14  founded_quarter       38482 non-null  object \n 15  founded_year          38482 non-null  float64\n 16  first_funding_at      49438 non-null  object \n 17  last_funding_at       49438 non-null  object \n 18  seed                  49438 non-null  float64\n 19  venture               49438 non-null  float64\n 20  equity_crowdfunding   49438 non-null  float64\n 21  undisclosed           49438 non-null  float64\n 22  convertible_note      49438 non-null  float64\n 23  debt_financing        49438 non-null  float64\n 24  angel                 49438 non-null  float64\n 25  grant                 49438 non-null  float64\n 26  private_equity        49438 non-null  float64\n 27  post_ipo_equity       49438 non-null  float64\n 28  post_ipo_debt         49438 non-null  float64\n 29  secondary_market      49438 non-null  float64\n 30  product_crowdfunding  49438 non-null  float64\n 31  round_A               49438 non-null  float64\n 32  round_B               49438 non-null  float64\n 33  round_C               49438 non-null  float64\n 34  round_D               49438 non-null  float64\n 35  round_E               49438 non-null  float64\n 36  round_F               49438 non-null  float64\n 37  round_G               49438 non-null  float64\n 38  round_H               49438 non-null  float64\ndtypes: float64(23), object(16)\nmemory usage: 12.8+ MB\nStarting data cleaning...\nStandardized column names.\nCleaning 'funding_total_usd'...\nDropped 13387 rows with missing/invalid 'funding_total_usd'.\nCleaning 'country_code' and renaming to 'country'...\nDropped 3819 rows with missing 'country'.\nCleaned 'country'.\nExtracting 'primary_category' from 'category_list'...\nExtracted 'primary_category'.\nCleaning date columns: ['founded_at', 'first_funding_at', 'last_funding_at']...\nCleaned date columns and extracted years.\nCleaning 'status' column...\nCleaned 'status' column.\nCleaning 'funding_rounds'...\nCleaned 'funding_rounds'.\nDropped 2 rows with missing 'first_funding_year'.\nData cleaning completed. Shape of cleaned data: (37086, 42)\n\n--- Missing Values Summary (Top 10) After Cleaning ---\nstate_code         11468\nfounded_month       7301\nfounded_quarter     7301\nfounded_at          7240\nfounded_year        7240\nhomepage_url        1879\nmarket              1844\ncategory_list       1841\ncity                 686\ndtype: int64\n\n--- Basic Exploratory Data Analysis (EDA) ---\n\n--- Descriptive Statistics for 'funding_total_usd' ---\ncount    3.708600e+04\nmean     1.688074e+07\nstd      1.768439e+08\nmin      1.400000e+01\n25%      4.450000e+05\n50%      2.200000e+06\n75%      1.011995e+07\nmax      3.007950e+10\nName: funding_total_usd, dtype: float64\n\n--- Value Counts for Top 5 Primary Categories ---\nprimary_category\nUnknown    37086\nName: count, dtype: int64\n\n--- Value Counts for Top 5 Countries ---\ncountry\nUSA    24476\nGBR     2284\nCAN     1165\nCHN      988\nFRA      766\nName: count, dtype: int64\n\n--- Value Counts for Company Status ---\nstatus\noperating    31209\nacquired      3062\nclosed        1866\nunknown        949\nName: count, dtype: int64\n\n--- Data Check for Potential KPIs ---\nData for KPI 'Total Funding by Year': Seems available.\nData for KPI 'Top N Countries by Funding': Seems available.\nData for KPI 'Top N Categories by Funding': Seems available.\nData for KPI 'Funding by Company Status': Seems available.\nData for KPI 'Average Funding per Round': Seems available.\nData for KPI 'Number of Investments Over Time': Seems available.\nData for KPI 'Distribution of Funding Amounts': Seems available.\nData for KPI 'Funding Rounds vs. Total Funding': Seems available.\nData for KPI 'Top Cities by Investment (if 'city' available)': Seems available.\nData for KPI 'Time from Founding to First Funding': Seems available.\n\nCleaned data successfully saved to 'cleaned_investments.csv'\n--- End of Startup Investment Data Processing ---\n"
        }
      ],
      "execution_count": 1
    },
    {
      "id": "53e144a3-9c6c-4766-8ae1-0cce0d931d9d",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}