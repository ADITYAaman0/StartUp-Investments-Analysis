# -*- coding: utf-8 -*-
"""Python Script: Data Processor (data_processor.py)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uIF1Rt-SAdWvJDOvAISp0rb_xnMa20im
"""

# data_processor.py
import pandas as pd
import numpy as np

# --- Configuration ---
# Ensure this matches your downloaded file name from Kaggle
INPUT_CSV_PATH = 'investments_VC.csv'
OUTPUT_CLEANED_CSV_PATH = 'cleaned_investments.csv'

# --- Load Data ---
def load_data(file_path):
    """
    Loads the raw dataset from a CSV file.
    Handles potential encoding issues common with this dataset.
    """
    print(f"Loading data from {file_path}...")
    try:
        # The dataset is known to sometimes have 'latin1' encoding issues.
        # If 'utf-8' fails, 'latin1' or 'iso-8859-1' are good alternatives to try.
        df = pd.read_csv(file_path, encoding='latin1')
        print("Data loaded successfully.")
        return df
    except FileNotFoundError:
        print(f"ERROR: File not found at {file_path}. Please ensure the dataset is in the correct location and the INPUT_CSV_PATH is correct.")
        return None
    except Exception as e:
        print(f"ERROR: An error occurred while loading the data: {e}")
        return None

# --- Clean Data ---
def clean_data(df):
    """
    Cleans the input DataFrame:
    - Standardizes column names.
    - Cleans and converts 'funding_total_usd'.
    - Cleans 'country_code' (renames to 'country') and handles missing values.
    - Extracts 'primary_category' from 'category_list'.
    - Converts date columns to datetime objects and extracts years.
    - Cleans 'status' and 'funding_rounds'.
    - Drops rows with critical missing data for analysis (e.g., funding_total_usd, first_funding_year).
    """
    if df is None:
        print("No DataFrame provided to clean_data function. Skipping.")
        return None
    print("Starting data cleaning...")
    df_cleaned = df.copy()

    # 1. Standardize column names
    # Remove leading/trailing spaces, convert to lowercase, replace spaces with underscores.
    df_cleaned.columns = df_cleaned.columns.str.strip().str.lower().str.replace(' ', '_')
    print("Standardized column names.")

    # 2. Handle 'funding_total_usd'
    # This is a critical column for almost all analyses.
    if 'funding_total_usd' in df_cleaned.columns:
        print("Cleaning 'funding_total_usd'...")
        # Original data has ' - ' for missing and commas as thousands separators.
        df_cleaned['funding_total_usd'] = df_cleaned['funding_total_usd'].astype(str).str.replace(',', '')
        df_cleaned['funding_total_usd'] = df_cleaned['funding_total_usd'].replace(' - ', np.nan) # Ensure '-' is treated as NaN
        df_cleaned['funding_total_usd'] = pd.to_numeric(df_cleaned['funding_total_usd'], errors='coerce')

        initial_rows = len(df_cleaned)
        df_cleaned.dropna(subset=['funding_total_usd'], inplace=True) # Essential for funding analysis
        print(f"Dropped {initial_rows - len(df_cleaned)} rows with missing/invalid 'funding_total_usd'.")
    else:
        print("WARNING: 'funding_total_usd' column not found after standardization. Check original column names and adjust if necessary.")
        # This is a critical failure point if the column isn't found.

    # 3. Handle 'country_code' (often used as 'country')
    if 'country_code' in df_cleaned.columns:
        print("Cleaning 'country_code' and renaming to 'country'...")
        df_cleaned.rename(columns={'country_code': 'country'}, inplace=True)
        df_cleaned['country'] = df_cleaned['country'].str.strip()
        # Drop rows where country is missing, as it's important for geographical analysis
        initial_rows_country = len(df_cleaned)
        df_cleaned.dropna(subset=['country'], inplace=True)
        print(f"Dropped {initial_rows_country - len(df_cleaned)} rows with missing 'country'.")
        print("Cleaned 'country'.")
    else:
        print("WARNING: 'country_code' column not found.")


    # 4. Handle 'category_list' (extract primary category)
    if 'category_list' in df_cleaned.columns:
        print("Extracting 'primary_category' from 'category_list'...")
        # Take the first category before the '|' delimiter.
        df_cleaned['primary_category'] = df_cleaned['category_list'].astype(str).apply(
            lambda x: x.split('|')[0].strip() if pd.notnull(x) and '|' in x else (x.strip() if pd.notnull(x) else 'Unknown')
        )
        # Handle cases where category might be empty string or 'nan' after split
        df_cleaned['primary_category'] = df_cleaned['primary_category'].replace({'nan': 'Unknown', '': 'Unknown'})
        df_cleaned.loc[df_cleaned['primary_category'].isnull(), 'primary_category'] = 'Unknown'
        print("Extracted 'primary_category'.")
    else:
        print("WARNING: 'category_list' column not found.")

    # 5. Handle Date Columns
    date_cols_to_process = ['founded_at', 'first_funding_at', 'last_funding_at']
    print(f"Cleaning date columns: {date_cols_to_process}...")
    for col in date_cols_to_process:
        if col in df_cleaned.columns:
            df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors='coerce')
            # Extract year for easier filtering and aggregation in Streamlit
            # Using .dt.year will result in float if there are NaT values, then convert to Int64 to support NA
            year_col_name = col.replace('_at', '_year')
            df_cleaned[year_col_name] = df_cleaned[col].dt.year.astype('Int64') # Int64 supports pandas NA
        else:
            print(f"WARNING: Date column '{col}' not found.")
    print("Cleaned date columns and extracted years.")

    # 6. Clean 'status' column
    if 'status' in df_cleaned.columns:
        print("Cleaning 'status' column...")
        df_cleaned['status'] = df_cleaned['status'].fillna('unknown').str.lower()
        # Consolidate status values if needed (e.g., map variations to standard terms)
        # Common values are 'operating', 'acquired', 'closed', 'ipo'.
        valid_statuses = ['operating', 'acquired', 'closed', 'ipo']
        df_cleaned['status'] = df_cleaned['status'].apply(lambda x: x if x in valid_statuses else 'unknown')
        print("Cleaned 'status' column.")
    else:
        print("WARNING: 'status' column not found.")

    # 7. Clean 'funding_rounds'
    if 'funding_rounds' in df_cleaned.columns:
        print("Cleaning 'funding_rounds'...")
        df_cleaned['funding_rounds'] = pd.to_numeric(df_cleaned['funding_rounds'], errors='coerce')
        df_cleaned.dropna(subset=['funding_rounds'], inplace=True) # Drop if not a number
        df_cleaned['funding_rounds'] = df_cleaned['funding_rounds'].astype(int)
        print("Cleaned 'funding_rounds'.")
    else:
        print("WARNING: 'funding_rounds' column not found.")

    # 8. Rename 'name' if it's messy (e.g. 'name ' with space)
    # Check if a common problematic name like 'name ' (with trailing space) exists and 'name' does not
    if 'name ' in df_cleaned.columns and 'name' not in df_cleaned.columns:
        df_cleaned.rename(columns={'name ': 'name'}, inplace=True)
        print("Renamed 'name ' to 'name'.")
    elif 'name' not in df_cleaned.columns:
         print("WARNING: Standard 'name' column not found. Company identification might be affected.")


    # 9. Drop rows where 'first_funding_year' is NaN as it's critical for many time-based analyses
    if 'first_funding_year' in df_cleaned.columns:
        initial_rows_ffy = len(df_cleaned)
        df_cleaned.dropna(subset=['first_funding_year'], inplace=True)
        # After dropping NaNs, we can safely convert to int if it's Int64
        df_cleaned['first_funding_year'] = df_cleaned['first_funding_year'].astype(int)
        print(f"Dropped {initial_rows_ffy - len(df_cleaned)} rows with missing 'first_funding_year'.")
    else:
        print("WARNING: 'first_funding_year' column not found or not processed. Time-based analysis will be affected.")


    print(f"Data cleaning completed. Shape of cleaned data: {df_cleaned.shape}")
    print("\n--- Missing Values Summary (Top 10) After Cleaning ---")
    # Display columns with the most missing values after cleaning
    missing_summary = df_cleaned.isnull().sum()
    missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)
    print(missing_summary.head(10))
    return df_cleaned

# --- Perform EDA (Conceptual - details in Analysis Report) ---
def perform_basic_eda(df):
    """
    Performs and prints basic Exploratory Data Analysis results.
    This is a lightweight EDA; more detailed EDA should be in the Analysis Report.
    """
    if df is None or df.empty:
        print("Skipping EDA as data is not available or empty.")
        return

    print("\n--- Basic Exploratory Data Analysis (EDA) ---")

    if 'funding_total_usd' in df.columns:
        print("\n--- Descriptive Statistics for 'funding_total_usd' ---")
        print(df['funding_total_usd'].describe())
    else:
        print("'funding_total_usd' not found for EDA.")

    if 'primary_category' in df.columns:
        print("\n--- Value Counts for Top 5 Primary Categories ---")
        print(df['primary_category'].value_counts().nlargest(5))
    else:
        print("'primary_category' not found for EDA.")

    if 'country' in df.columns:
        print("\n--- Value Counts for Top 5 Countries ---")
        print(df['country'].value_counts().nlargest(5))
    else:
        print("'country' not found for EDA.")

    if 'status' in df.columns:
        print("\n--- Value Counts for Company Status ---")
        print(df['status'].value_counts())
    else:
        print("'status' not found for EDA.")

    # Check availability of data for potential KPIs (to be visualized in Streamlit)
    print("\n--- Data Check for Potential KPIs ---")
    kpi_columns_to_check = {
        "Total Funding by Year": ['first_funding_year', 'funding_total_usd'],
        "Top N Countries by Funding": ['country', 'funding_total_usd'],
        "Top N Categories by Funding": ['primary_category', 'funding_total_usd'],
        "Funding by Company Status": ['status', 'funding_total_usd'],
        "Average Funding per Round": ['funding_total_usd', 'funding_rounds'],
        "Number of Investments Over Time": ['first_funding_year', 'name'], # Using 'name' as a proxy for unique investment
        "Distribution of Funding Amounts": ['funding_total_usd'],
        "Funding Rounds vs. Total Funding": ['funding_rounds', 'funding_total_usd'],
        "Top Cities by Investment (if 'city' available)": ['city', 'funding_total_usd'],
        "Time from Founding to First Funding": ['founded_year', 'first_funding_year']
    }
    for kpi, cols in kpi_columns_to_check.items():
        missing_cols = [col for col in cols if col not in df.columns or df[col].isnull().all()]
        if not missing_cols:
            print(f"Data for KPI '{kpi}': Seems available.")
        else:
            print(f"Data for KPI '{kpi}': MISSING or all NaNs for columns: {missing_cols}")


# --- Main Execution Block ---
if __name__ == "__main__":
    print("--- Starting Startup Investment Data Processing ---")
    raw_df = load_data(INPUT_CSV_PATH)

    if raw_df is not None:
        print("\n--- Initial Data Info (First 5 Rows & Column Info) ---")
        print("Head of raw data:")
        print(raw_df.head())
        print("\nInfo of raw data:")
        raw_df.info(verbose=True, show_counts=True) # More detailed info

        cleaned_df = clean_data(raw_df)

        if cleaned_df is not None and not cleaned_df.empty:
            perform_basic_eda(cleaned_df)
            # Save the cleaned data to a new CSV file
            try:
                cleaned_df.to_csv(OUTPUT_CLEANED_CSV_PATH, index=False)
                print(f"\nCleaned data successfully saved to '{OUTPUT_CLEANED_CSV_PATH}'")
            except Exception as e:
                print(f"ERROR: Could not save cleaned data: {e}")
        else:
            print("Cleaned data is empty or None. Not performing EDA or saving.")
    else:
        print("Raw data could not be loaded. Processing halted.")
    print("--- End of Startup Investment Data Processing ---")

# exploratory_data_analysis.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# --- Configuration ---
CLEANED_DATA_PATH = 'cleaned_investments.csv'
TOP_N = 10 # For top N listings

# --- Plotting Style ---
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 7) # Default figure size
plt.rcParams['font.size'] = 12

# --- Load Data ---
def load_data(file_path):
    """Loads the cleaned dataset."""
    print(f"Loading cleaned data from {file_path}...")
    try:
        df = pd.read_csv(file_path)
        # Ensure 'first_funding_year' is int, if it exists
        if 'first_funding_year' in df.columns:
            df['first_funding_year'] = pd.to_numeric(df['first_funding_year'], errors='coerce').fillna(0).astype(int)
        print("Cleaned data loaded successfully.")
        return df
    except FileNotFoundError:
        print(f"ERROR: File not found at {file_path}. Please ensure 'data_processor.py' has been run and '{CLEANED_DATA_PATH}' exists.")
        return None
    except Exception as e:
        print(f"ERROR: An error occurred while loading the cleaned data: {e}")
        return None

# --- EDA Functions ---

def display_total_funding(df):
    """Calculates and displays the total funding raised across all startups."""
    if 'funding_total_usd' not in df.columns:
        print("ERROR: 'funding_total_usd' column not found.")
        return
    total_funding = df['funding_total_usd'].sum()
    print(f"\n--- 1. Total Funding Raised ---")
    print(f"Total funding raised across all startups: ${total_funding:,.0f}")

def display_top_funded_companies(df, n=TOP_N):
    """Displays and visualizes the top N funded companies."""
    if 'name' not in df.columns or 'funding_total_usd' not in df.columns:
        print("ERROR: 'name' or 'funding_total_usd' column not found for top funded companies.")
        return
    print(f"\n--- 2. Top {n} Funded Companies ---")
    top_companies = df.groupby('name')['funding_total_usd'].sum().nlargest(n).sort_values(ascending=False)
    print(top_companies)

    plt.figure()
    top_companies.sort_values(ascending=True).plot(kind='barh', color=sns.color_palette("viridis", n))
    plt.title(f'Top {n} Most Funded Companies')
    plt.xlabel('Total Funding (USD)')
    plt.ylabel('Company Name')
    plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: "${:,.0f}".format(x)))
    plt.tight_layout()
    plt.show()

def display_funding_by_country(df, n=TOP_N):
    """Displays and visualizes the distribution of funding by top N countries."""
    if 'country' not in df.columns or 'funding_total_usd' not in df.columns:
        print("ERROR: 'country' or 'funding_total_usd' column not found for funding by country.")
        return
    print(f"\n--- 3. Distribution of Funding by Top {n} Countries ---")
    funding_by_country = df.groupby('country')['funding_total_usd'].sum().nlargest(n).sort_values(ascending=False)
    print(funding_by_country)

    plt.figure()
    funding_by_country.sort_values(ascending=True).plot(kind='barh', color=sns.color_palette("magma", n))
    plt.title(f'Top {n} Countries by Total Funding Received')
    plt.xlabel('Total Funding (USD)')
    plt.ylabel('Country')
    plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: "${:,.0f}".format(x)))
    plt.tight_layout()
    plt.show()

def display_most_active_markets(df, n=TOP_N):
    """Displays and visualizes the most active markets (primary categories by number of unique startups)."""
    if 'primary_category' not in df.columns or 'name' not in df.columns:
        print("ERROR: 'primary_category' or 'name' column not found for active markets.")
        return
    print(f"\n--- 4. Top {n} Most Active Markets (by Number of Unique Startups) ---")
    # Count unique companies per category
    active_markets = df.groupby('primary_category')['name'].nunique().nlargest(n).sort_values(ascending=False)
    print(active_markets)

    plt.figure()
    active_markets.sort_values(ascending=True).plot(kind='barh', color=sns.color_palette("coolwarm", n))
    plt.title(f'Top {n} Most Active Markets (by Number of Unique Startups)')
    plt.xlabel('Number of Unique Startups')
    plt.ylabel('Primary Category')
    plt.tight_layout()
    plt.show()

def display_funding_trends_over_years(df):
    """Displays and visualizes funding trends over the years."""
    if 'first_funding_year' not in df.columns or 'funding_total_usd' not in df.columns:
        print("ERROR: 'first_funding_year' or 'funding_total_usd' column not found for funding trends.")
        return
    print(f"\n--- 5. Funding Trends Over Years ---")
    # Filter out potential placeholder years like 0 if they exist from fillna(0)
    funding_by_year = df[df['first_funding_year'] > 1900].groupby('first_funding_year')['funding_total_usd'].sum()
    print(funding_by_year.tail()) # Print last few years

    plt.figure()
    funding_by_year.plot(kind='line', marker='o', color='teal')
    plt.title('Total Funding Raised Over Years')
    plt.xlabel('Year of First Funding')
    plt.ylabel('Total Funding (USD)')
    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: "${:,.0f}".format(x)))
    plt.grid(True, which='both', linestyle='--', linewidth=0.5)
    plt.tight_layout()
    plt.show()

def display_status_distribution(df):
    """Displays and visualizes the distribution of startup statuses."""
    if 'status' not in df.columns:
        print("ERROR: 'status' column not found for status distribution.")
        return
    print(f"\n--- 6. Startup Status Distribution ---")
    status_counts = df['status'].value_counts()
    print(status_counts)

    plt.figure(figsize=(8,8)) # Pie charts often look better square
    status_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=sns.color_palette("pastel"))
    plt.title('Distribution of Startup Statuses')
    plt.ylabel('') # Hide the default 'status' ylabel from pie charts
    plt.tight_layout()
    plt.show()

def display_funding_rounds_vs_total_funding_correlation(df):
    """Calculates and visualizes the correlation between funding rounds and total funding."""
    if 'funding_rounds' not in df.columns or 'funding_total_usd' not in df.columns:
        print("ERROR: 'funding_rounds' or 'funding_total_usd' column not found for correlation.")
        return
    print(f"\n--- 7. Correlation between Funding Rounds and Total Funding ---")

    # For better visualization, especially with outliers, consider log scale or filtering extreme values
    # Here, we'll plot a sample to avoid overplotting if the dataset is huge.
    sample_df = df.sample(n=min(1000, len(df)), random_state=42) if len(df) > 1000 else df

    correlation = df['funding_rounds'].corr(df['funding_total_usd'])
    print(f"Pearson Correlation Coefficient: {correlation:.2f}")

    plt.figure()
    sns.scatterplot(data=sample_df, x='funding_rounds', y='funding_total_usd', alpha=0.5, color='dodgerblue')
    # Optional: Log scale for y-axis if funding amounts are highly skewed
    # plt.yscale('log')
    # plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: "${:,.0f}".format(x))) # if log scale
    plt.title('Funding Rounds vs. Total Funding')
    plt.xlabel('Number of Funding Rounds')
    plt.ylabel('Total Funding (USD)')
    plt.text(0.05, 0.95, f'Correlation: {correlation:.2f}', transform=plt.gca().transAxes,
             fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.5))
    plt.tight_layout()
    plt.show()

def note_on_top_investors():
    """Provides a note on the complexity of analyzing top investors with the current data."""
    print(f"\n--- 8. Note on Top Investors (Seed/Venture Rounds) ---")
    print("Analyzing top investors and distinguishing between seed/venture rounds requires structured data on investors and round types.")
    print("The current `cleaned_investments.csv` (based on `data_processor_py_v2`) does not have a dedicated, cleaned column for individual investor names or clearly separated round types for this specific analysis.")
    print("If the original `investments_VC.csv` contains an 'investors' column, it would need specific parsing logic (e.g., splitting multiple investor names, identifying round types from other columns or keywords) to extract this insight accurately.")
    print("This step is beyond the scope of the current EDA script using the provided cleaned data structure.")

# --- Main Execution ---
if __name__ == "__main__":
    print("--- Starting Exploratory Data Analysis for Startup Investments ---")
    df_cleaned = load_data(CLEANED_DATA_PATH)

    if df_cleaned is not None and not df_cleaned.empty:
        # Perform EDA
        display_total_funding(df_cleaned)
        display_top_funded_companies(df_cleaned)
        display_funding_by_country(df_cleaned)
        display_most_active_markets(df_cleaned)
        display_funding_trends_over_years(df_cleaned)
        display_status_distribution(df_cleaned)
        display_funding_rounds_vs_total_funding_correlation(df_cleaned)
        note_on_top_investors()

        print("\n--- EDA Completed ---")
        print("Plots have been displayed. If running in a non-interactive environment, plots might be saved or not shown automatically.")
    else:
        print("Could not perform EDA as the cleaned data is not available or empty.")