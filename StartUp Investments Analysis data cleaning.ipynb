# -*- coding: utf-8 -*-
"""Python Script: Data Processor (data_processor.py)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iCo_pf-JvVYZyz_F7lp8m_ZVhRI0IrdK
"""

import pandas as pd
import numpy as np


INPUT_CSV_PATH = 'investments_VC.csv'
OUTPUT_CLEANED_CSV_PATH = 'cleaned_investments.csv'


def load_data(file_path):

    print(f"Loading data from {file_path}...")
    try:
        # The dataset is known to sometimes have 'latin1' encoding issues.
        # If 'utf-8' fails, 'latin1' or 'iso-8859-1' are good alternatives to try.
        df = pd.read_csv(file_path, encoding='latin1')
        print("Data loaded successfully.")
        return df
    except FileNotFoundError:
        print(f"ERROR: File not found at {file_path}. Please ensure the dataset is in the correct location and the INPUT_CSV_PATH is correct.")
        return None
    except Exception as e:
        print(f"ERROR: An error occurred while loading the data: {e}")
        return None


def clean_data(df):

    if df is None:
        print("No DataFrame provided to clean_data function. Skipping.")
        return None
    print("Starting data cleaning...")
    df_cleaned = df.copy()

    df_cleaned.columns = df_cleaned.columns.str.strip().str.lower().str.replace(' ', '_')
    print("Standardized column names.")

    if 'funding_total_usd' in df_cleaned.columns:
        print("Cleaning 'funding_total_usd'...")
        # Original data has ' - ' for missing and commas as thousands separators.
        df_cleaned['funding_total_usd'] = df_cleaned['funding_total_usd'].astype(str).str.replace(',', '')
        df_cleaned['funding_total_usd'] = df_cleaned['funding_total_usd'].replace(' - ', np.nan) # Ensure '-' is treated as NaN
        df_cleaned['funding_total_usd'] = pd.to_numeric(df_cleaned['funding_total_usd'], errors='coerce')

        initial_rows = len(df_cleaned)
        df_cleaned.dropna(subset=['funding_total_usd'], inplace=True) # Essential for funding analysis
        print(f"Dropped {initial_rows - len(df_cleaned)} rows with missing/invalid 'funding_total_usd'.")
    else:
        print("WARNING: 'funding_total_usd' column not found after standardization. Check original column names and adjust if necessary.")
        # This is a critical failure point if the column isn't found.

    if 'country_code' in df_cleaned.columns:
        print("Cleaning 'country_code' and renaming to 'country'...")
        df_cleaned.rename(columns={'country_code': 'country'}, inplace=True)
        df_cleaned['country'] = df_cleaned['country'].str.strip()
        # Drop rows where country is missing, as it's important for geographical analysis
        initial_rows_country = len(df_cleaned)
        df_cleaned.dropna(subset=['country'], inplace=True)
        print(f"Dropped {initial_rows_country - len(df_cleaned)} rows with missing 'country'.")
        print("Cleaned 'country'.")
    else:
        print("WARNING: 'country_code' column not found.")


    if 'category_list' in df_cleaned.columns:
        print("Extracting 'primary_category' from 'category_list'...")

        df_cleaned['primary_category'] = df_cleaned['category_list'].astype(str).apply(
            lambda x: x.split('|')[0].strip() if pd.notnull(x) and '|' in x else (x.strip() if pd.notnull(x) else 'Unknown')
        )

        df_cleaned['primary_category'] = df_cleaned['primary_category'].replace({'nan': 'Unknown', '': 'Unknown'})
        df_cleaned.loc[df_cleaned['primary_category'].isnull(), 'primary_category'] = 'Unknown'
        print("Extracted 'primary_category'.")
    else:
        print("WARNING: 'category_list' column not found.")

    date_cols_to_process = ['founded_at', 'first_funding_at', 'last_funding_at']
    print(f"Cleaning date columns: {date_cols_to_process}...")
    for col in date_cols_to_process:
        if col in df_cleaned.columns:
            df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors='coerce')

            year_col_name = col.replace('_at', '_year')
            df_cleaned[year_col_name] = df_cleaned[col].dt.year.astype('Int64') # Int64 supports pandas NA
        else:
            print(f"WARNING: Date column '{col}' not found.")
    print("Cleaned date columns and extracted years.")


    if 'status' in df_cleaned.columns:
        print("Cleaning 'status' column...")
        df_cleaned['status'] = df_cleaned['status'].fillna('unknown').str.lower()

        valid_statuses = ['operating', 'acquired', 'closed', 'ipo']
        df_cleaned['status'] = df_cleaned['status'].apply(lambda x: x if x in valid_statuses else 'unknown')
        print("Cleaned 'status' column.")
    else:
        print("WARNING: 'status' column not found.")


    if 'funding_rounds' in df_cleaned.columns:
        print("Cleaning 'funding_rounds'...")
        df_cleaned['funding_rounds'] = pd.to_numeric(df_cleaned['funding_rounds'], errors='coerce')
        df_cleaned.dropna(subset=['funding_rounds'], inplace=True) # Drop if not a number
        df_cleaned['funding_rounds'] = df_cleaned['funding_rounds'].astype(int)
        print("Cleaned 'funding_rounds'.")
    else:
        print("WARNING: 'funding_rounds' column not found.")


    if 'name ' in df_cleaned.columns and 'name' not in df_cleaned.columns:
        df_cleaned.rename(columns={'name ': 'name'}, inplace=True)
        print("Renamed 'name ' to 'name'.")
    elif 'name' not in df_cleaned.columns:
         print("WARNING: Standard 'name' column not found. Company identification might be affected.")


    if 'city' in df_cleaned.columns:
        print("Cleaning 'city'...")
        df_cleaned['city'] = df_cleaned['city'].str.strip()
        print("Cleaned 'city'.")
    if 'first_funding_year' in df_cleaned.columns:
        initial_rows_ffy = len(df_cleaned)
        df_cleaned.dropna(subset=['first_funding_year'], inplace=True)

        df_cleaned['first_funding_year'] = df_cleaned['first_funding_year'].astype(int)
        print(f"Dropped {initial_rows_ffy - len(df_cleaned)} rows with missing 'first_funding_year'.")
    else:
        print("WARNING: 'first_funding_year' column not found or not processed. Time-based analysis will be affected.")


    print(f"Data cleaning completed. Shape of cleaned data: {df_cleaned.shape}")
    print("\n--- Missing Values Summary (Top 10) After Cleaning ---")

    missing_summary = df_cleaned.isnull().sum()
    missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)
    print(missing_summary.head(10))
    return df_cleaned

def perform_basic_eda(df):
    """
    Performs and prints basic Exploratory Data Analysis results.
    This is a lightweight EDA; more detailed EDA should be in the Analysis Report.
    """
    if df is None or df.empty:
        print("Skipping EDA as data is not available or empty.")
        return

    print("\n--- Basic Exploratory Data Analysis (EDA) ---")

    if 'funding_total_usd' in df.columns:
        print("\n--- Descriptive Statistics for 'funding_total_usd' ---")
        print(df['funding_total_usd'].describe())
    else:
        print("'funding_total_usd' not found for EDA.")

    if 'primary_category' in df.columns:
        print("\n--- Value Counts for Top 5 Primary Categories ---")
        print(df['primary_category'].value_counts().nlargest(5))
    else:
        print("'primary_category' not found for EDA.")

    if 'country' in df.columns:
        print("\n--- Value Counts for Top 5 Countries ---")
        print(df['country'].value_counts().nlargest(5))
    else:
        print("'country' not found for EDA.")

    if 'status' in df.columns:
        print("\n--- Value Counts for Company Status ---")
        print(df['status'].value_counts())
    else:
        print("'status' not found for EDA.")


    print("\n--- Data Check for Potential KPIs ---")
    kpi_columns_to_check = {
        "Total Funding by Year": ['first_funding_year', 'funding_total_usd'],
        "Top N Countries by Funding": ['country', 'funding_total_usd'],
        "Top N Categories by Funding": ['primary_category', 'funding_total_usd'],
        "Funding by Company Status": ['status', 'funding_total_usd'],
        "Average Funding per Round": ['funding_total_usd', 'funding_rounds'],
        "Number of Investments Over Time": ['first_funding_year', 'name'], # Using 'name' as a proxy for unique investment
        "Distribution of Funding Amounts": ['funding_total_usd'],
        "Funding Rounds vs. Total Funding": ['funding_rounds', 'funding_total_usd'],
        "Top Cities by Investment (if 'city' available)": ['city', 'funding_total_usd'],
        "Time from Founding to First Funding": ['founded_year', 'first_funding_year']
    }
    for kpi, cols in kpi_columns_to_check.items():
        missing_cols = [col for col in cols if col not in df.columns or df[col].isnull().all()]
        if not missing_cols:
            print(f"Data for KPI '{kpi}': Seems available.")
        else:
            print(f"Data for KPI '{kpi}': MISSING or all NaNs for columns: {missing_cols}")

if __name__ == "__main__":
    print("--- Starting Startup Investment Data Processing ---")
    raw_df = load_data(INPUT_CSV_PATH)

    if raw_df is not None:
        print("\n--- Initial Data Info (First 5 Rows & Column Info) ---")
        print("Head of raw data:")
        print(raw_df.head())
        print("\nInfo of raw data:")
        raw_df.info(verbose=True, show_counts=True)

        cleaned_df = clean_data(raw_df)

        if cleaned_df is not None and not cleaned_df.empty:
            perform_basic_eda(cleaned_df)

            try:
                cleaned_df.to_csv(OUTPUT_CLEANED_CSV_PATH, index=False)
                print(f"\nCleaned data successfully saved to '{OUTPUT_CLEANED_CSV_PATH}'")
            except Exception as e:
                print(f"ERROR: Could not save cleaned data: {e}")
        else:
            print("Cleaned data is empty or None. Not performing EDA or saving.")
    else:
        print("Raw data could not be loaded. Processing halted.")
    print("--- End of Startup Investment Data Processing ---")